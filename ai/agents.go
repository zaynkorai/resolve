package ai

import (
	"context"
	"fmt"
	"strings"

	"github.com/google/generative-ai-go/genai"
	"github.com/zaynkorai/resolve/prompts"
	"google.golang.org/api/option"
)

type LLMClient interface {
	GenerateContent(ctx context.Context, parts ...genai.Part) (*genai.GenerateContentResponse, error)
}

type GeminiClient struct {
	model *genai.GenerativeModel
}

func NewGeminiClient(ctx context.Context, apiKey string) (*GeminiClient, error) {
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return nil, fmt.Errorf("error creating Gemini client: %w", err)
	}

	model := client.GenerativeModel("gemini-2.0-flash")
	model.SetTemperature(0.1)

	return &GeminiClient{model: model}, nil
}

func (g *GeminiClient) GenerateContent(ctx context.Context, parts ...genai.Part) (*genai.GenerateContentResponse, error) {
	resp, err := g.model.GenerateContent(ctx, parts...)
	if err != nil {
		return nil, fmt.Errorf("failed to generate content with Gemini: %w", err)
	}
	return resp, nil
}

// A helper to call the LLM and get plain text output.
func CallLLMForTextOutput(ctx context.Context, client LLMClient, prompt string) (string, error) {
	resp, err := client.GenerateContent(ctx, genai.Text(prompt))
	if err != nil {
		return "", fmt.Errorf("LLM call failed: %w", err)
	}

	if resp == nil || len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return "", fmt.Errorf("no content generated by LLM")
	}

	var sb strings.Builder
	for _, part := range resp.Candidates[0].Content.Parts {
		if text, ok := part.(genai.Text); ok {
			sb.WriteString(string(text))
		}
	}
	return sb.String(), nil
}

type Agents struct {
	gemini *GeminiClient
}

// NewAgents creates and initializes the Agents struct with the Gemini client.
// It requires a context and your Google API Key.
func NewAgents(ctx context.Context, googleAPIKey string) (*Agents, error) {
	geminiClient, err := NewGeminiClient(ctx, googleAPIKey)
	if err != nil {
		return nil, fmt.Errorf("failed to initialize Gemini client: %w", err)
	}

	return &Agents{
		gemini: geminiClient,
	}, nil
}

func (a *Agents) ResolveGivenIssue(ctx context.Context, contextStr, question string) (string, error) {
	prompt := fmt.Sprintf(prompts.RESOLVE_ISSUE, contextStr, question)
	answer, err := CallLLMForTextOutput(ctx, a.gemini, prompt)
	if err != nil {
		return "", fmt.Errorf("failed to generate RAG answer: %w", err)
	}
	return answer, nil
}
